{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be1c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc.math import exp\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fe5c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gastric cancer example\n",
    "\n",
    "Adapted from code for [Unit 8: gastric.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/gastric.odc).\n",
    "\n",
    "Data can be found [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/gastric.txt).\n",
    "\n",
    "Associated lecture video: Unit 8 lesson 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e3f25",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "Stablein et al. (1981) provide data on 90 patients affected by locally advanced, nonresectable gastric carcinoma. The patients are randomized to two treatments: chemotherapy alone (coded as 0) and chemotherapy plus radiation (coded as 1). Survival time is reported in days. Recorded times are censored if the patient stopped participating in the study before it finished.\n",
    "\n",
    "Stablein, D. M., Carter, W. H., Novak, J. W. (1981). Analysis of survival data with nonproportional hazard functions. Control. Clin. Trials,  2 , 2, 149--159.\n",
    "\n",
    "### Data\n",
    "Columns are, from left to right:\n",
    "- type: Treatment type, chemotherapy (0) or chemotherapy + radiation (1)\n",
    "- censored: If censored, meaning the patient survived the observation period, the time in days appears here rather than in the times column. 0 if not censored.\n",
    "- times: Recorded days without cancer recurrence. NaN if censored.\n",
    "\n",
    "### Model changes\n",
    "PyMC really did not like the noninformative exponential prior on v (α in this model). It's a very broad prior. To avoid divide by zero errors, I just kept increasing lambda until the model ran all the way through. This is not ideal, but I haven't had time to look into it further. The results actually came out fairly close to the BUGS results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf06b6",
   "metadata": {},
   "source": [
    "## Method 1: ```pm.Censored```\n",
    "\n",
    "The way PyMC censoring works is described in some detail in [this notebook](https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-truncated-censored-regression.html#censored-regression-model) by [Dr. Benjamin T. Vincent](https://github.com/drbenvincent). This is accomplished in the source code [here](https://github.com/aesara-devs/aeppl/blob/751979802f1aef5478fdbf7cc1839df07df60825/aeppl/truncation.py#L79) if you want to take a look. For right-censoring, try this: ```pm.Censored(\"name\", dist, lower=None, upper=censored, observed=y)```. The censored values can be an array of the same shape as the y values. \n",
    "\n",
    "If the y value equals the right-censored value, [```pm.Censored```](https://docs.pymc.io/en/latest/api/distributions/generated/pymc.Censored.html#pymc.Censored) returns the complement to the CDF evaluated at the censored value. If the y value is greater than the censored value, it returns ```-np.inf```. Otherwise, the distribution you passed to the ```dist``` parameter works as normal. What I've been doing is setting the values in the censored array to ```np.inf``` if the corresponding y value is not censored, and equal to the y value if it should be censored.\n",
    "\n",
    "```{note}\n",
    "I've noticed that this method is unstable with some distributions. Try using the imputed censoring model (below) if this one isn't working.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edcd8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"../data/gastric.txt\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3958f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, 0].copy()\n",
    "censored = data[:, 1].copy()\n",
    "y = data[:, 2].copy()\n",
    "# for pymc, right-censored values must be greater than or equal to than the \"upper\" value\n",
    "y[np.isnan(y)] = censored[np.isnan(y)]\n",
    "censored[censored == 0] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8deab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17.,   42.,   44.,   48.,   60.,   72.,   74.,   95.,  103.,\n",
       "        108.,  122.,  144.,  167.,  170.,  183.,  185.,  193.,  195.,\n",
       "        197.,  208.,  234.,  235.,  254.,  307.,  315.,  401.,  445.,\n",
       "        464.,  484.,  528.,  542.,  567.,  577.,  580.,  795.,  855.,\n",
       "        882.,  892., 1031., 1033., 1306., 1335., 1366., 1452., 1472.,\n",
       "          1.,   63.,  105.,  129.,  182.,  216.,  250.,  262.,  301.,\n",
       "        301.,  342.,  354.,  356.,  358.,  380.,  381.,  383.,  383.,\n",
       "        388.,  394.,  408.,  460.,  489.,  499.,  524.,  529.,  535.,\n",
       "        562.,  675.,  676.,  748.,  748.,  778.,  786.,  797.,  945.,\n",
       "        955.,  968., 1180., 1245., 1271., 1277., 1397., 1512., 1519.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab73347f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,\n",
       "        882.,  892., 1031., 1033., 1306., 1335.,   inf, 1452., 1472.,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,  381.,   inf,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,  529.,   inf,\n",
       "         inf,   inf,   inf,   inf,   inf,   inf,   inf,   inf,  945.,\n",
       "         inf,   inf, 1180.,   inf,   inf, 1277., 1397., 1512., 1519.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c9b58",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "PyMC and BUGS do not specify the Weibull distribution in the same way!\n",
    "\n",
    "α = v\n",
    "\n",
    "β = λ ** (-1 / α)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bbe3f2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [beta0, beta1, α]\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/aesaraf.py:387: UserWarning: No value variable found for weibull_rv{0, (0, 0), floatX, False}.out; the random variable will not be replaced.\n",
      "  warnings.warn(\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/aesaraf.py:387: UserWarning: No value variable found for weibull_rv{0, (0, 0), floatX, False}.out; the random variable will not be replaced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 00:14&lt;00:00 Sampling 4 chains, 1 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 24 seconds.\n",
      "The acceptance probability does not match the target. It is 0.8957, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "log2 = np.log(2)\n",
    "\n",
    "with pm.Model() as m:\n",
    "    beta0 = pm.Normal(\"beta0\", 0, tau=0.01)\n",
    "    beta1 = pm.Normal(\"beta1\", 0, tau=0.1)\n",
    "    α = pm.Exponential(\"α\", 4)\n",
    "\n",
    "    λ = exp(beta0 + beta1 * x)\n",
    "    β = λ ** (-1 / α)\n",
    "\n",
    "    obs_latent = pm.Weibull.dist(alpha=α, beta=β)\n",
    "    likelihood = pm.Censored(\n",
    "        \"likelihood\",\n",
    "        obs_latent,\n",
    "        lower=None,\n",
    "        upper=censored,\n",
    "        observed=y,\n",
    "    )\n",
    "\n",
    "    median0 = pm.Deterministic(\"median0\", (log2 * exp(-beta0)) ** (1 / α))\n",
    "    median1 = pm.Deterministic(\"median1\", (log2 * exp(-beta0 - beta1)) ** (1 / α))\n",
    "\n",
    "    # update these variable names later\n",
    "    S = pm.Deterministic(\"S\", exp(-λ * (likelihood**α)))\n",
    "    f = pm.Deterministic(\"f\", λ * α * (likelihood ** (α - 1)) * S)\n",
    "    h = pm.Deterministic(\"h\", f / S)\n",
    "\n",
    "    trace = pm.sample(\n",
    "        10000,\n",
    "        tune=2000,\n",
    "        cores=4,\n",
    "        init=\"jitter+adapt_diag_grad\",\n",
    "        step=[pm.NUTS(target_accept=0.9)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95b02cb",
   "metadata": {
    "tags": [
     "full-width"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5%</th>\n",
       "      <th>hdi_95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta0</th>\n",
       "      <td>-6.527</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-7.609</td>\n",
       "      <td>-5.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta1</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median0</th>\n",
       "      <td>515.526</td>\n",
       "      <td>90.306</td>\n",
       "      <td>371.411</td>\n",
       "      <td>659.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median1</th>\n",
       "      <td>398.197</td>\n",
       "      <td>71.489</td>\n",
       "      <td>284.688</td>\n",
       "      <td>514.198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean      sd   hdi_5%  hdi_95%\n",
       "beta0     -6.527   0.652   -7.609   -5.479\n",
       "beta1      0.254   0.233   -0.127    0.636\n",
       "α          0.988   0.095    0.831    1.143\n",
       "median0  515.526  90.306  371.411  659.033\n",
       "median1  398.197  71.489  284.688  514.198"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, var_names=[\"~S\", \"~f\", \"~h\"], kind=\"stats\", hdi_prob=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d25dde",
   "metadata": {},
   "source": [
    "## Method 2: Imputed Censoring\n",
    "This method is from [this notebook](https://www.pymc.io/projects/examples/en/latest/survival_analysis/censored_data.html#censored-data-model1) by [Luis Mario Domenzain](https://github.com/domenzain), [George Ho](https://github.com/eigenfoo), and [Dr. Ben Vincent](https://github.com/drbenvincent). This method imputes the values using what is almost another likelihood (not sure if it actually meets the definition of one, so I'm calling the variable ```impute_censored```) in the model, with the right-censored values as lower bounds. Since the two likelihoods share the same priors, this ends up working nearly as well as the previous method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8eece9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../data/gastric.txt\")\n",
    "x = data[:, 0].copy()\n",
    "censored_vals = data[:, 1].copy()\n",
    "y = data[:, 2].copy()\n",
    "\n",
    "# we need to separate the observed values and the censored values\n",
    "observed_mask = censored_vals == 0\n",
    "\n",
    "censored = censored_vals[~observed_mask]\n",
    "y_uncensored = y[observed_mask]\n",
    "x_censored = x[~observed_mask]\n",
    "x_uncensored = x[observed_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad4328",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "log2 = np.log(2)\n",
    "\n",
    "with pm.Model() as m:\n",
    "    beta0 = pm.Normal(\"beta0\", 0, tau=0.0001)\n",
    "    beta1 = pm.Normal(\"beta1\", 0, tau=0.0001)\n",
    "    α = pm.Exponential(\"α\", 3)\n",
    "\n",
    "    λ_censored = exp(beta0 + beta1 * x_censored)\n",
    "    β_censored = λ_censored ** (-1 / α)\n",
    "\n",
    "    λ_uncensored = exp(beta0 + beta1 * x_uncensored)\n",
    "    β_uncensored = λ_uncensored ** (-1 / α)\n",
    "\n",
    "    impute_censored = pm.Bound(\n",
    "        \"impute_censored\",\n",
    "        pm.Weibull.dist(alpha=α, beta=β_censored),\n",
    "        lower=censored,\n",
    "        shape=censored.shape[0],\n",
    "    )\n",
    "\n",
    "    likelihood = pm.Weibull(\n",
    "        \"likelihood\",\n",
    "        alpha=α,\n",
    "        beta=β_uncensored,\n",
    "        observed=y_uncensored,\n",
    "        shape=y_uncensored.shape[0],\n",
    "    )\n",
    "\n",
    "    median0 = pm.Deterministic(\"median0\", (log2 * exp(-beta0)) ** (1 / α))\n",
    "    median1 = pm.Deterministic(\"median1\", (log2 * exp(-beta0 - beta1)) ** (1 / α))\n",
    "\n",
    "    trace = pm.sample(\n",
    "        10000, tune=2000, cores=4, init=\"auto\", step=[pm.NUTS(target_accept=0.95)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec317b",
   "metadata": {
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "az.summary(trace, hdi_prob=0.9, kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad87b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -n -u -v -iv -p aesara,aeppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58558621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
